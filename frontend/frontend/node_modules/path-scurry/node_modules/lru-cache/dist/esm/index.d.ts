/**
 * @module LRUCache
 */
declare const TYPE: unique symbol;
export type PosInt = number & {
    [TYPE]: 'Positive Integer';
};
export type Index = number & {
    [TYPE]: 'LRUCache Index';
};
export type UintArray = Uint8Array | Uint16Array | Uint32Array;
export type NumberArray = UintArray | number[];
declare class ZeroArray extends Array<number> {
    constructor(size: number);
}
export type { ZeroArray };
export type { Stack };
export type StackLike = Stack | Index[];
declare class Stack {
    #private;
    heap: NumberArray;
    length: number;
    static create(max: number): StackLike;
    constructor(max: number, HeapCls: {
        new (n: number): NumberArray;
    });
    push(n: Index): void;
    pop(): Index;
}
/**
 * Promise representing an in-progress {@link LRUCache#fetch} call
 */
export type BackgroundFetch<V> = Promise<V | undefined> & {
    __returned: BackgroundFetch<V> | undefined;
    __abortController: AbortController;
    __staleWhileFetching: V | undefined;
};
export type DisposeTask<K, V> = [
    value: V,
    key: K,
    reason: LRUCache.DisposeReason
];
export declare namespace LRUCache {
    /**
     * An integer greater than 0, reflecting the calculated size of items
     */
    type Size = number;
    /**
     * Integer greater than 0, representing some number of milliseconds, or the
     * time at which a TTL started counting from.
     */
    type Milliseconds = number;
    /**
     * An integer greater than 0, reflecting a number of items
     */
    type Count = number;
    /**
     * The reason why an item was removed from the cache, passed
     * to the {@link Disposer} methods.
     *
     * - `evict`: The item was evicted because it is the least recently used,
     *   and the cache is full.
     * - `set`: A new value was set, overwriting the old value being disposed.
     * - `delete`: The item was explicitly deleted, either by calling
     *   {@link LRUCache#delete}, {@link LRUCache#clear}, or
     *   {@link LRUCache#set} with an undefined value.
     * - `expire`: The item was removed due to exceeding its TTL.
     * - `fetch`: A {@link OptionsBase#fetchMethod} operation returned
     *   `undefined` or was aborted, causing the item to be deleted.
     */
    type DisposeReason = 'evict' | 'set' | 'delete' | 'expire' | 'fetch';
    /**
     * A method called upon item removal, passed as the
     * {@link OptionsBase.dispose} and/or
     * {@link OptionsBase.disposeAfter} options.
     */
    type Disposer<K, V> = (value: V, key: K, reason: DisposeReason) => void;
    /**
     * A function that returns the effective calculated size
     * of an entry in the cache.
     */
    type SizeCalculator<K, V> = (value: V, key: K) => Size;
    /**
     * Options provided to the
     * {@link OptionsBase.fetchMethod} function.
     */
    interface FetcherOptions<K, V, FC = unknown> {
        signal: AbortSignal;
        options: FetcherFetchOptions<K, V, FC>;
        /**
         * Object provided in the {@link FetchOptions.context} option to
         * {@link LRUCache#fetch}
         */
        context: FC;
    }
    /**
     * Occasionally, it may be useful to track the internal behavior of the
     * cache, particularly for logging, debugging, or for behavior within the
     * `fetchMethod`. To do this, you can pass a `status` object to the
     * {@link LRUCache#fetch}, {@link LRUCache#get}, {@link LRUCache#set},
     * {@link LRUCache#memo}, and {@link LRUCache#has} methods.
     *
     * The `status` option should be a plain JavaScript object. The following
     * fields will be set on it appropriately, depending on the situation.
     */
    interface Status<V> {
        /**
         * The status of a set() operation.
         *
         * - add: the item was not found in the cache, and was added
         * - update: the item was in the cache, with the same value provided
         * - replace: the item was in the cache, and replaced
         * - miss: the item was not added to the cache for some reason
         */
        set?: 'add' | 'update' | 'replace' | 'miss';
        /**
         * the ttl stored for the item, or undefined if ttls are not used.
         */
        ttl?: Milliseconds;
        /**
         * the start time for the item, or undefined if ttls are not used.
         */
        start?: Milliseconds;
        /**
         * The timestamp used for TTL calculation
         */
        now?: Milliseconds;
        /**
         * the remaining ttl for the item, or undefined if ttls are not used.
         */
        remainingTTL?: Milliseconds;
        /**
         * The calculated size for the item, if sizes are used.
         */
        entrySize?: Size;
        /**
         * The total calculated size of the cache, if sizes are used.
         */
        totalCalculatedSize?: Size;
        /**
         * A flag indicating that the item was not stored, due to exceeding the
         * {@link OptionsBase.maxEntrySize}
         */
        maxEntrySizeExceeded?: true;
        /**
         * The old value, specified in the case of `set:'update'` or
         * `set:'replace'`
         */
        oldValue?: V;
        /**
         * The results of a {@link LRUCache#has} operation
         *
         * - hit: the item was found in the cache
         * - stale: the item was found in the cache, but is stale
         * - miss: the item was not found in the cache
         */
        has?: 'hit' | 'stale' | 'miss';
        /**
         * The status of a {@link LRUCache#fetch} operation.
         * Note that this can change as the underlying fetch() moves through
         * various states.
         *
         * - inflight: there is another fetch() for this key which is in process
         * - get: there is no {@link OptionsBase.fetchMethod}, so
         *   {@link LRUCache#get} was called.
         * - miss: the item is not in cache, and will be fetched.
         * - hit: the item is in the cache, and was resolved immediately.
         * - stale: the item is in the cache, but stale.
         * - refresh: the item is in the cache, and not stale, but
         *   {@link FetchOptions.forceRefresh} was specified.
         */
        fetch?: 'get' | 'inflight' | 'miss' | 'hit' | 'stale' | 'refresh';
        /**
         * The {@link OptionsBase.fetchMethod} was called
         */
        fetchDispatched?: true;
        /**
         * The cached value was updated after a successful call to
         * {@link OptionsBase.fetchMethod}
         */
        fetchUpdated?: true;
        /**
         * The reason for a fetch() rejection.  Either the error raised by the
         * {@link OptionsBase.fetchMethod}, or the reason for an
         * AbortSignal.
         */
        fetchError?: Error;
        /**
         * The fetch received an abort signal
         */
        fetchAborted?: true;
        /**
         * The abort signal received was ignored, and the fetch was allowed to
         * continue.
         */
        fetchAbortIgnored?: true;
        /**
         * The fetchMethod promise resolved successfully
         */
        fetchResolved?: true;
        /**
         * The fetchMethod promise was rejected
         */
        fetchRejected?: true;
        /**
         * The status of a {@link LRUCache#get} operation.
         *
         * - fetching: The item is currently being fetched.  If a previous value
         *   is present and allowed, that will be returned.
         * - stale: The item is in the cache, and is stale.
         * - hit: the item is in the cache
         * - miss: the item is not in the cache
         */
        get?: 'stale' | 'hit' | 'miss';
        /**
         * A fetch or get operation returned a stale value.
         */
        returnedStale?: true;
    }
    /**
     * options which override the options set in the LRUCache constructor
     * when calling {@link LRUCache#fetch}.
     *
     * This is the union of {@link GetOptions} and {@link SetOptions}, plus
     * {@link OptionsBase.noDeleteOnFetchRejection},
     * {@link OptionsBase.allowStaleOnFetchRejection},
     * {@link FetchOptions.forceRefresh}, and
     * {@link FetcherOptions.context}
     *
     * Any of these may be modified in the {@link OptionsBase.fetchMethod}
     * function, but the {@link GetOptions} fields will of course have no
     * effect, as the {@link LRUCache#get} call already happened by the time
     * the fetchMethod is called.
     */
    interface FetcherFetchOptions<K, V, FC = unknown> extends Pick<OptionsBase<K, V, FC>, 'allowStale' | 'updateAgeOnGet' | 'noDeleteOnStaleGet' | 'sizeCalculation' | 'ttl' | 'noDisposeOnSet' | 'noUpdateTTL' | 'noDeleteOnFetchRejection' | 'allowStaleOnFetchRejection' | 'ignoreFetchAbort' | 'allowStaleOnFetchAbort'> {
        status?: Status<V>;
        size?: Size;
    }
    /**
     * Options that may be passed to the {@link LRUCache#fetch} method.
     */
    interface FetchOptions<K, V, FC> extends FetcherFetchOptions<K, V, FC> {
        /**
         * Set to true to force a re-load of the existing data, even if it
         * is not yet stale.
         */
        forceRefresh?: boolean;
        /**
         * Context provided to the {@link OptionsBase.fetchMethod} as
         * the {@link FetcherOptions.context} param.
         *
         * If the FC type is specified as unknown (the default),
         * undefined or void, then this is optional.  Otherwise, it will
         * be required.
         */
        context?: FC;
        signal?: AbortSignal;
        status?: Status<V>;
    }
    /**
     * Options provided to {@link LRUCache#fetch} when the FC type is something
     * other than `unknown`, `undefined`, or `void`
     */
    interface FetchOptionsWithContext<K, V, FC> extends FetchOptions<K, V, FC> {
        context: FC;
    }
    /**
     * Options provided to {@link LRUCache#fetch} when the FC type is
     * `undefined` or `void`
     */
    interface FetchOptionsNoContext<K, V> extends FetchOptions<K, V, undefined> {
        context?: undefined;
    }
    interface MemoOptions<K, V, FC = unknown> extends Pick<OptionsBase<K, V, FC>, 'allowStale' | 'updateAgeOnGet' | 'noDeleteOnStaleGet' | 'sizeCalculation' | 'ttl' | 'noDisposeOnSet' | 'noUpdateTTL' | 'noDeleteOnFetchRejection' | 'allowStaleOnFetchRejection' | 'ignoreFetchAbort' | 'allowStaleOnFetchAbort'> {
        /**
         * Set to true to force a re-load of the existing data, even if it
         * is not yet stale.
         */
        forceRefresh?: boolean;
        /**
         * Context provided to the {@link OptionsBase.memoMethod} as
         * the {@link MemoizerOptions.context} param.
         *
         * If the FC type is specified as unknown (the default),
         * undefined or void, then this is optional.  Otherwise, it will
         * be required.
         */
        context?: FC;
        status?: Status<V>;
    }
    /**
     * Options provided to {@link LRUCache#memo} when the FC type is something
     * other than `unknown`, `undefined`, or `void`
     */
    interface MemoOptionsWithContext<K, V, FC> extends MemoOptions<K, V, FC> {
        context: FC;
    }
    /**
     * Options provided to {@link LRUCache#memo} when the FC type is
     * `undefined` or `void`
     */
    interface MemoOptionsNoContext<K, V> extends MemoOptions<K, V, undefined> {
        context?: undefined;
    }
    /**
     * Options provided to the
     * {@link OptionsBase.memoMethod} function.
     */
    interface MemoizerOptions<K, V, FC = unknown> {
        options: MemoizerMemoOptions<K, V, FC>;
        /**
         * Object provided in the {@link MemoOptions.context} option to
         * {@link LRUCache#memo}
         */
        context: FC;
    }
    /**
     * options which override the options set in the LRUCache constructor
     * when calling {@link LRUCache#memo}.
     *
     * This is the union of {@link GetOptions} and {@link SetOptions}, plus
     * {@link MemoOptions.forceRefresh}, and
     * {@link MemoerOptions.context}
     *
     * Any of these may be modified in the {@link OptionsBase.memoMethod}
     * function, but the {@link GetOptions} fields will of course have no
     * effect, as the {@link LRUCache#get} call already happened by the time
     * the memoMethod is called.
     */
    interface MemoizerMemoOptions<K, V, FC = unknown> extends Pick<OptionsBase<K, V, FC>, 'allowStale' | 'updateAgeOnGet' | 'noDeleteOnStaleGet' | 'sizeCalculation' | 'ttl' | 'noDisposeOnSet' | 'noUpdateTTL'> {
        status?: Status<V>;
        size?: Size;
        start?: Milliseconds;
    }
    /**
     * Options that may be passed to the {@link LRUCache#has} method.
     */
    interface HasOptions<K, V, FC> extends Pick<OptionsBase<K, V, FC>, 'updateAgeOnHas'> {
        status?: Status<V>;
    }
    /**
     * Options that may be passed to the {@link LRUCache#get} method.
     */
    interface GetOptions<K, V, FC> extends Pick<OptionsBase<K, V, FC>, 'allowStale' | 'updateAgeOnGet' | 'noDeleteOnStaleGet'> {
        status?: Status<V>;
    }
    /**
     * Options that may be passed to the {@link LRUCache#peek} method.
     */
    interface PeekOptions<K, V, FC> extends Pick<OptionsBase<K, V, FC>, 'allowStale'> {
    }
    /**
     * Options that may be passed to the {@link LRUCache#set} method.
     */
    interface SetOptions<K, V, FC> extends Pick<OptionsBase<K, V, FC>, 'sizeCalculation' | 'ttl' | 'noDisposeOnSet' | 'noUpdateTTL'> {
        /**
         * If size tracking is enabled, then setting an explicit size
         * in the {@link LRUCache#set} call will prevent calling the
         * {@link OptionsBase.sizeCalculation} function.
         */
        size?: Size;
        /**
         * If TTL tracking is enabled, then setting an explicit start
         * time in the {@link LRUCache#set} call will override the
         * default time from `performance.now()` or `Date.now()`.
         *
         * Note that it must be a valid value for whichever time-tracking
         * method is in use.
         */
        start?: Milliseconds;
        status?: Status<V>;
    }
    /**
     * The type signature for the {@link OptionsBase.fetchMethod} option.
     */
    type Fetcher<K, V, FC = unknown> = (key: K, staleValue: V | undefined, options: FetcherOptions<K, V, FC>) => Promise<V | undefined | void> | V | undefined | void;
    /**
     * the type signature for the {@link OptionsBase.memoMethod} option.
     */
    type Memoizer<K, V, FC = unknown> = (key: K, staleValue: V | undefined, options: MemoizerOptions<K, V, FC>) => V;
    /**
     * Options which may be passed to the {@link LRUCache} constructor.
     *
     * Most of these may be overridden in the various options that use
     * them.
     *
     * Despite all being technically optional, the constructor requires that
     * a cache is at minimum limited by one or more of {@link OptionsBase.max},
     * {@link OptionsBase.ttl}, or {@link OptionsBase.maxSize}.
     *
     * If {@link OptionsBase.ttl} is used alone, then it is strongly advised
     * (and in fact required by the type definitions here) that the cache
     * also set {@link OptionsBase.ttlAutopurge}, to prevent potentially
     * unbounded storage.
     *
     * All options are also available on the {@link LRUCache} instance, making
     * it safe to pass an LRUCache instance as the options argumemnt to
     * make another empty cache of the same type.
     *
     * Some options are marked as read-only, because changing them after
     * instantiation is not safe. Changing any of the other options will of
     * course only have an effect on subsequent method calls.
     */
    interface OptionsBase<K, V, FC> {
        /**
         * The maximum number of items to store in the cache before evicting
         * old entries. This is read-only on the {@link LRUCache} instance,
         * and may not be overridden.
         *
         * If set, then storage space will be pre-allocated at construction
         * time, and the cache will perform significantly faster.
         *
         * Note that significantly fewer items may be stored, if
         * {@link OptionsBase.maxSize} and/or {@link OptionsBase.ttl} are also
         * set.
         *
         * **It is strongly recommended to set a `max` to prevent unbounded growth
         * of the cache.**
         */
        max?: Count;
        /**
         * Max time in milliseconds for items to live in cache before they are
         * considered stale.  Note that stale items are NOT preemptively removed by
         * default, and MAY live in the cache, contributing to its LRU max, long
         * after they have expired, unless {@link OptionsBase.ttlAutopurge} is
         * set.
         *
         * If set to `0` (the default value), then that means "do not track
         * TTL", not "expire immediately".
         *
         * Also, as this cache is optimized for LRU/MRU operations, some of
         * the staleness/TTL checks will reduce performance, as they will incur
         * overhead by deleting items.
         *
         * This is not primarily a TTL cache, and does not make strong TTL
         * guarantees. There is no pre-emptive pruning of expired items, but you
         * _may_ set a TTL on the cache, and it will treat expired items as missing
         * when they are fetched, and delete them.
         *
         * Optional, but must be a non-negative integer in ms if specified.
         *
         * This may be overridden by passing an options object to `cache.set()`.
         *
         * At least one of `max`, `maxSize`, or `TTL` is required. This must be a
         * positive integer if set.
         *
         * Even if ttl tracking is enabled, **it is strongly recommended to set a
         * `max` to prevent unbounded growth of the cache.**
         *
         * If ttl tracking is enabled, and `max` and `maxSize` are not set,
         * and `ttlAutopurge` is not set, then a warning will be emitted
         * cautioning about the potential for unbounded memory consumption.
         * (The TypeScript definitions will also discourage this.)
         */
        ttl?: Milliseconds;
        /**
         * Minimum amount of time in ms in which to check for staleness.
         * Defaults to 1, which means that the current time is checked
         * at most once per millisecond.
         *
         * Set to 0 to check the current time every time staleness is tested.
         * (This reduces performance, and is theoretically unnecessary.)
         *
         * Setting this to a higher value will improve performance somewhat
         * while using ttl tracking, albeit at the expense of keeping stale
         * items around a bit longer than their TTLs would indicate.
         *
         * @default 1
         */
        ttlResolution?: Milliseconds;
        /**
         * Preemptively remove stale items from the cache.
         *
         * Note that this may *significantly* degrade performance, especially if
         * the cache is storing a large number of items. It is almost always best
         * to just leave the stale items in the cache, and let them fall out as new
         * items are added.
         *
         * Note that this means that {@link OptionsBase.allowStale} is a bit
         * pointless, as stale items will be deleted almost as soon as they
         * expire.
         *
         * Use with caution!
         */
        ttlAutopurge?: boolean;
        /**
         * When using time-expiring entries with `ttl`, setting this to `true` will
         * make each item's age reset to 0 whenever it is retrieved from cache with
         * {@link LRUCache#get}, causing it to not expire. (It can still fall out
         * of cache based on recency of use, of course.)
         *
         * Has no effect if {@link OptionsBase.ttl} is not set.
         *
         * This may be overridden by passing an options object to `cache.get()`.
         */
        updateAgeOnGet?: boolean;
        /**
         * When using time-expiring entries with `ttl`, setting this to `true` will
         * make each item's age reset to 0 whenever its presence in the cache is
         * checked with {@link LRUCache#has}, causing it to not expire. (It can
         * still fall out of cache based on recency of use, of course.)
         *
         * Has no effect if {@link OptionsBase.ttl} is not set.
         */
        updateAgeOnHas?: boolean;
        /**
         * Allow {@link LRUCache#get} and {@link LRUCache#fetch} calls to return
         * stale data, if available.
         *
         * By default, if you set `ttl`, stale items will only be deleted from the
         * cache when you `get(key)`. That is, it's not preemptively pruning items,
         * unless {@link OptionsBase.ttlAutopurge} is set.
         *
         * If you set `allowStale:true`, it'll return the stale value *as well as*
         * deleting it. If you don't set this, then it'll return `undefined` when
         * you try to get a stale entry.
         *
         * Note that when a stale entry is fetched, _even if it is returned due to
         * `allowStale` being set_, it is removed from the cache immediately. You
         * can suppress this behavior by setting
         * {@link OptionsBase.noDeleteOnStaleGet}, either in the constructor, or in
         * the options provided to {@link LRUCache#get}.
         *
         * This may be overridden by passing an options object to `cache.get()`.
         * The `cache.has()` method will always return `false` for stale items.
         *
         * Only relevant if a ttl is set.
         */
        allowStale?: boolean;
        /**
         * Function that is called on items when they are dropped from the
         * cache, as `dispose(value, key, reason)`.
         *
         * This can be handy if you want to close file descriptors or do
         * other cleanup tasks when items are no longer stored in the cache.
         *
         * **NOTE**: It is called _before_ the item has been fully removed
         * from the cache, so if you want to put it right back in, you need
         * to wait until the next tick. If you try to add it back in during
         * the `dispose()` function call, it will break things in subtle and
         * weird ways.
         *
         * Unlike several other options, this may _not_ be overridden by
         * passing an option to `set()`, for performance reasons.
         *
         * The `reason` will be one of the following strings, corresponding
         * 